apiVersion: kubeflow.org/v1
kind: Notebook
metadata:
  annotations:
    notebooks.opendatahub.io/inject-oauth: 'true'
    opendatahub.io/image-display-name: oai-hadoop-spark-notebook-20250705-204615
    notebooks.opendatahub.io/oauth-logout-url: 'https://rhods-dashboard-redhat-ods-applications.apps.ocp.home.glroland.com/projects/fraud-detection?notebookLogout=oai-hadoop-spark'
    opendatahub.io/accelerator-name: ''
    openshift.io/description: ''
    openshift.io/display-name: oai-hadoop-spark
    notebooks.opendatahub.io/last-image-version-git-commit-selection: ''
    notebooks.opendatahub.io/last-image-selection: 'oai-hadoop-spark-notebook-20250705-204615:oai-hadoop-spark-notebook-20250705-204615'
    opendatahub.io/hardware-profile-namespace: ''
    notebooks.opendatahub.io/last-size-selection: ''
    opendatahub.io/username: admin
    opendatahub.io/hardware-profile-name: small-notebooks-1bmle
  name: oai-hadoop-spark
  namespace: fraud-detection
  labels:
    app: oai-hadoop-spark
    opendatahub.io/dashboard: 'true'
    opendatahub.io/odh-managed: 'true'
    opendatahub.io/user: admin
spec:
  template:
    spec:
      containers:
        - resources:
            limits:
              cpu: '1'
              memory: 8Gi
            requests:
              cpu: '1'
              memory: 8Gi
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /notebook/fraud-detection/oai-hadoop-spark/api
              port: notebook-port
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          name: oai-hadoop-spark
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /notebook/fraud-detection/oai-hadoop-spark/api
              port: notebook-port
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          env:
            - name: NOTEBOOK_ARGS
              value: |-
                --ServerApp.port=8888
                                  --ServerApp.token=''
                                  --ServerApp.password=''
                                  --ServerApp.base_url=/notebook/fraud-detection/oai-hadoop-spark
                                  --ServerApp.quit_button=False
                                  --ServerApp.tornado_settings={"user":"admin","hub_host":"https://rhods-dashboard-redhat-ods-applications.apps.ocp.home.glroland.com","hub_prefix":"/projects/fraud-detection"}
            - name: JUPYTER_IMAGE
              value: 'oai-hadoop-spark-notebook-20250705-204615:oai-hadoop-spark-notebook-20250705-204615'
            - name: PIPELINES_SSL_SA_CERTS
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
            - name: GIT_SSL_CAINFO
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
            - name: PIP_CERT
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
            - name: REQUESTS_CA_BUNDLE
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
            - name: SSL_CERT_FILE
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
          ports:
            - containerPort: 8888
              name: notebook-port
              protocol: TCP
            - containerPort: 20000
              name: pyspark-executor-port
              protocol: TCP
          imagePullPolicy: Always
          volumeMounts:
            - mountPath: /opt/app-root/src/
              name: oai-hadoop-spark-storage
            - mountPath: /opt/app-root/runtimes
              name: elyra-dsp-details
            - mountPath: /dev/shm
              name: shm
            - mountPath: /etc/pki/tls/custom-certs/ca-bundle.crt
              name: trusted-ca
              readOnly: true
              subPath: ca-bundle.crt
            - mountPath: /opt/app-root/pipeline-runtimes/
              name: runtime-images
          image: 'registry.home.glroland.com/paas/oai-hadoop-spark-notebook:20250706-153835'
          workingDir: /opt/app-root/src
        - resources:
            limits:
              cpu: 100m
              memory: 64Mi
            requests:
              cpu: 100m
              memory: 64Mi
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /oauth/healthz
              port: oauth-proxy
              scheme: HTTPS
            initialDelaySeconds: 5
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          name: oauth-proxy
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /oauth/healthz
              port: oauth-proxy
              scheme: HTTPS
            initialDelaySeconds: 30
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          env:
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          ports:
            - containerPort: 8443
              name: oauth-proxy
              protocol: TCP
          imagePullPolicy: Always
          volumeMounts:
            - mountPath: /etc/oauth/client
              name: oauth-client
            - mountPath: /etc/oauth/config
              name: oauth-config
            - mountPath: /etc/tls/private
              name: tls-certificates
          image: 'registry.home.glroland.com/paas/oai-hadoop-spark-notebook:20250706-153835'
          args:
            - '--provider=openshift'
            - '--https-address=:8443'
            - '--http-address='
            - '--openshift-service-account=oai-hadoop-spark'
            - '--cookie-secret-file=/etc/oauth/config/cookie_secret'
            - '--cookie-expire=24h0m0s'
            - '--tls-cert=/etc/tls/private/tls.crt'
            - '--tls-key=/etc/tls/private/tls.key'
            - '--upstream=http://localhost:8888'
            - '--upstream-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
            - '--email-domain=*'
            - '--skip-provider-button'
            - '--client-id=oai-hadoop-spark-fraud-detection-oauth-client'
            - '--client-secret-file=/etc/oauth/client/secret'
            - '--scope=user:info user:check-access'
            - '--openshift-sar={"verb":"get","resource":"notebooks","resourceAPIGroup":"kubeflow.org","resourceName":"oai-hadoop-spark","namespace":"$(NAMESPACE)"}'
            - '--logout-url=https://rhods-dashboard-redhat-ods-applications.apps.ocp.home.glroland.com/projects/fraud-detection?notebookLogout=oai-hadoop-spark'
      enableServiceLinks: false
      serviceAccountName: oai-hadoop-spark
      volumes:
        - name: oai-hadoop-spark-storage
          persistentVolumeClaim:
            claimName: oai-hadoop-spark-storage
        - name: elyra-dsp-details
          secret:
            optional: true
            secretName: ds-pipeline-config
        - emptyDir:
            medium: Memory
          name: shm
        - configMap:
            items:
              - key: ca-bundle.crt
                path: ca-bundle.crt
            name: workbench-trusted-ca-bundle
            optional: true
          name: trusted-ca
        - configMap:
            name: pipeline-runtime-images
            optional: true
          name: runtime-images
        - name: oauth-config
          secret:
            defaultMode: 420
            secretName: oai-hadoop-spark-oauth-config
        - name: oauth-client
          secret:
            defaultMode: 420
            secretName: oai-hadoop-spark-oauth-client
        - name: tls-certificates
          secret:
            defaultMode: 420
            secretName: oai-hadoop-spark-tls
